{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3208050e-31b0-4989-a1f6-130ad0af59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy as gp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "from gurobipy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b87edc94-76d5-4f08-8690-18a85a916ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fish = pd.read_excel(\"fish.xlsx\")\n",
    "species_meta = pd.read_excel(\"species.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba2c1d4-88b2-463f-9974-b5f40cb0c836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final cleaned dataset shape: (89, 32)\n"
     ]
    }
   ],
   "source": [
    "species_cols = [c for c in fish.columns if c.startswith(\"SPECIES\")]\n",
    "for col in species_cols:\n",
    "    fish[col] = fish[col].fillna(0)\n",
    "    fish[col] = (fish[col].astype(float) != 0).astype(int)\n",
    "    \n",
    "print(\"Final cleaned dataset shape:\", fish.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b0817b6-a22c-401d-8144-43e483d13f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_species = {}\n",
    "\n",
    "for col in species_cols:\n",
    "    species_name = col.strip()\n",
    "    if species_name not in clean_species:\n",
    "        clean_species[species_name] = fish[col]\n",
    "    else:\n",
    "        # Combine duplicate columns\n",
    "        clean_species[species_name] = clean_species[species_name].combine(fish[col], func=lambda a,b: max(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc4fb69d-142b-4302-9e4c-315b1e9e43c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(68, 32)\n",
      "Final cleaned dataset shape: (68, 32)\n"
     ]
    }
   ],
   "source": [
    "species_df = pd.DataFrame(clean_species)\n",
    "fish_clean = fish.drop(columns=species_cols).join(species_df)\n",
    "species_cols_final = list(species_df.columns)\n",
    "fish_clean[\"species_sum\"] = fish_clean[species_cols_final].sum(axis=1)\n",
    "\n",
    "fish_clean = fish_clean[fish_clean[\"species_sum\"] > 0].copy()\n",
    "fish_clean.drop(columns=[\"species_sum\"], inplace=True)\n",
    "fish_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "fish_clean = (\n",
    "    fish_clean\n",
    "    .sort_values([\"Coordinates\", \"Catches\"], ascending=[True, False])\n",
    "    .drop_duplicates(subset=\"Coordinates\", keep=\"first\")\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(fish_clean.shape)\n",
    "print(\"Final cleaned dataset shape:\", fish_clean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25afc744-36ac-4d50-b1ed-7c4d5518a02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched species: ['American shad', 'Black crappie', 'Carpe', 'Catfish', 'Common mullet', 'Common shiner', 'Creek chub', 'Goldeye', 'Lake trout', 'Largemouth bass', 'Muskellunge', 'Northern pike', 'Pumpkinseed', 'Redhorse', 'Rock bass', 'Sauger', 'Sheephead', 'Smallmouth Bass', 'Striped bass', 'Sturgeon', 'Sunfish', 'Tench', 'Walleye', 'Yellow bullhead', 'Yellow perch']\n",
      "Unmatched species: []\n"
     ]
    }
   ],
   "source": [
    "species_cols = [c for c in fish_clean.columns if c.startswith(\"SPECIES\")]\n",
    "\n",
    "def extract_species_name(colname: str) -> str:\n",
    "    \"\"\"Get the text inside parentheses: 'SPECIES (Walleye)' -> 'Walleye'.\"\"\"\n",
    "    m = re.search(r'\\((.*?)\\)', colname)\n",
    "    if m:\n",
    "        return m.group(1).strip()\n",
    "    return colname.replace(\"SPECIES\", \"\").replace(\"(\", \"\").replace(\")\", \"\").strip()\n",
    "\n",
    "fish_species_names = sorted({extract_species_name(c) for c in species_cols})\n",
    "\n",
    "def norm_name(s: str) -> str:\n",
    "    \"\"\"Normalize species names for matching: lowercase, letters only.\"\"\"\n",
    "    return re.sub(r'[^a-z]', '', str(s).lower())\n",
    "\n",
    "# normalized names in each source\n",
    "fish_species_norm = {s: norm_name(s) for s in fish_species_names}\n",
    "species_meta[\"Fish_norm\"] = species_meta[\"Fish\"].apply(norm_name)\n",
    "\n",
    "# ---------------------------------------------------\n",
    "# 3. Map fish species to species_meta rows\n",
    "# ---------------------------------------------------\n",
    "species_mapping = {}  # key: fish species name, value: index in species_meta\n",
    "unmatched_species = []\n",
    "\n",
    "for s in fish_species_names:\n",
    "    norm_s = fish_species_norm[s]\n",
    "    matches = species_meta.index[species_meta[\"Fish_norm\"] == norm_s].tolist()\n",
    "    if matches:\n",
    "        species_mapping[s] = matches[0]\n",
    "    else:\n",
    "        unmatched_species.append(s)\n",
    "\n",
    "print(\"Matched species:\", list(species_mapping.keys()))\n",
    "print(\"Unmatched species:\", unmatched_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7be64ba9-f261-4926-8309-942e0b3f6f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced dataset shape: (20, 32)\n",
      "Top sites used (Name and Catches):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Catches</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lac Saint-Fran√ßois</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fleuve st laurent</td>\n",
       "      <td>1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bassin du P√™cheur</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canal de Lachine</td>\n",
       "      <td>601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ruisseau Bouchard</td>\n",
       "      <td>552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Baie de Quenneville</td>\n",
       "      <td>528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ruisseau Hotte</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Canal Lachine</td>\n",
       "      <td>506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bassin de Chambly</td>\n",
       "      <td>455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>parc bellerive</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Rapides du Grand Moulin</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rapides de Vaudreuil</td>\n",
       "      <td>376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Rapides de Cap-Saint-Jacques</td>\n",
       "      <td>369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Lake saint louie</td>\n",
       "      <td>279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Rivi√®re L'Assomption</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lac des deux montagne</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Baie de Valois</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Les Faucilles</td>\n",
       "      <td>221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Mouillage Longueuil</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Canal de l'Aqueduc</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  Catches\n",
       "0             Lac Saint-Fran√ßois     1477\n",
       "1              Fleuve st laurent     1303\n",
       "2              Bassin du P√™cheur      741\n",
       "3               Canal de Lachine      601\n",
       "4              Ruisseau Bouchard      552\n",
       "5            Baie de Quenneville      528\n",
       "6                 Ruisseau Hotte      515\n",
       "7                  Canal Lachine      506\n",
       "8              Bassin de Chambly      455\n",
       "9                 parc bellerive      416\n",
       "10       Rapides du Grand Moulin      400\n",
       "11         Rapides de Vaudreuil¬†      376\n",
       "12  Rapides de Cap-Saint-Jacques      369\n",
       "13              Lake saint louie      279\n",
       "14          Rivi√®re L'Assomption      251\n",
       "15        Lac des deux montagne¬†      240\n",
       "16                Baie de Valois      226\n",
       "17                 Les Faucilles      221\n",
       "18           Mouillage Longueuil      206\n",
       "19            Canal de l'Aqueduc      205"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOP_N_SITES = 20\n",
    "\n",
    "fish_clean = (\n",
    "    fish_clean\n",
    "    .sort_values(\"Catches\", ascending=False)\n",
    "    .head(TOP_N_SITES)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "print(\"Reduced dataset shape:\", fish_clean.shape)\n",
    "print(\"Top sites used (Name and Catches):\")\n",
    "display(fish_clean[[\"Name\", \"Catches\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a172dff9-a61f-4bc4-b0a9-45b96a00c3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "      >>> FISHING TRIP CONFIGURATOR (EFFICIENCY MODE) <<<\n",
      "============================================================\n",
      "\n",
      "[1] Target Species\n",
      "    Examples: Smallmouth Bass, Walleye, Northern pike\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üëâ Enter species:  Largemouth bass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2] Preferred Baits\n",
      "    Options: soft, hard, natural\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üëâ Enter baits:  soft\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[3] Preferred Rod\n",
      "    Options: short, medium, long\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "üëâ Enter rods:  medium\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Configured for Efficiency: Stops when Limit is reached.\n",
      "============================================================\n",
      "\n",
      "\n",
      "--- Optimizing ---\n",
      "Set parameter TimeLimit to value 60\n",
      "Gurobi Optimizer version 12.0.3 build v12.0.3rc0 (win64 - Windows 11.0 (26100.2))\n",
      "\n",
      "CPU model: 13th Gen Intel(R) Core(TM) i9-13900HX, instruction set [SSE2|AVX|AVX2]\n",
      "Thread count: 24 physical cores, 32 logical processors, using up to 32 threads\n",
      "\n",
      "Non-default parameters:\n",
      "TimeLimit  60\n",
      "\n",
      "Optimize a model with 1924 rows, 1871 columns and 6257 nonzeros\n",
      "Model fingerprint: 0x4f2cf96d\n",
      "Variable types: 202 continuous, 1669 integer (1548 binary)\n",
      "Coefficient statistics:\n",
      "  Matrix range     [2e-01, 2e+01]\n",
      "  Objective range  [5e-01, 5e+01]\n",
      "  Bounds range     [1e+00, 1e+00]\n",
      "  RHS range        [1e+00, 2e+01]\n",
      "Found heuristic solution: objective -4.3145495\n",
      "Presolve removed 1239 rows and 1492 columns\n",
      "Presolve time: 0.06s\n",
      "Presolved: 685 rows, 379 columns, 2259 nonzeros\n",
      "Variable types: 43 continuous, 336 integer (271 binary)\n",
      "\n",
      "Root relaxation: objective 1.694159e+01, 64 iterations, 0.00 seconds (0.00 work units)\n",
      "\n",
      "    Nodes    |    Current Node    |     Objective Bounds      |     Work\n",
      " Expl Unexpl |  Obj  Depth IntInf | Incumbent    BestBd   Gap | It/Node Time\n",
      "\n",
      "     0     0   16.94159    0    8   -4.31455   16.94159   493%     -    0s\n",
      "H    0     0                      -2.7340890   16.94159   720%     -    0s\n",
      "H    0     0                       6.9744707   16.94159   143%     -    0s\n",
      "H    0     0                      10.8604494   16.94159  56.0%     -    0s\n",
      "H    0     0                      14.8870056   16.94159  13.8%     -    0s\n",
      "H    0     0                      14.9261013   16.94159  13.5%     -    0s\n",
      "     0     0   15.78978    0   15   14.92610   15.78978  5.79%     -    0s\n",
      "     0     0   15.78978    0    7   14.92610   15.78978  5.79%     -    0s\n",
      "     0     0   15.51486    0   15   14.92610   15.51486  3.94%     -    0s\n",
      "     0     0   14.92610    0    7   14.92610   14.92610  0.00%     -    0s\n",
      "\n",
      "Cutting planes:\n",
      "  Learned: 2\n",
      "  Gomory: 1\n",
      "  Implied bound: 2\n",
      "  Flow cover: 1\n",
      "  Relax-and-lift: 1\n",
      "\n",
      "Explored 1 nodes (198 simplex iterations) in 0.12 seconds (0.06 work units)\n",
      "Thread count was 32 (of 32 available processors)\n",
      "\n",
      "Solution count 7: 14.9261 14.887 14.094 ... -4.31455\n",
      "\n",
      "Optimal solution found (tolerance 1.00e-04)\n",
      "Best objective 1.492610130833e+01, best bound 1.492610130833e+01, gap 0.0000%\n",
      "\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "üé£  FISHING TRIP SUMMARY (Obj: 14.93)\n",
      "‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n",
      "‚è±Ô∏è  Duration : 12.00 / 12.0 hrs\n",
      "üêü  Real Catch: 6  (Keep: 6 | Release: 0)\n",
      "üìç  Districts : South\n",
      "-----------------------------------------------------------------------------------------------\n",
      "\n",
      "üöó  TRIP ITINERARY\n",
      "  McGill                    -> Baie de Valois (16)       : DRIVE üöó  [0.30h (+0.50h prep)]\n",
      "  Baie de Valois (16)       -> Lake saint louie (13)     : WALK üö∂   [0.37h]\n",
      "  Lake saint louie (13)     -> Baie de Quenneville (5)   : DRIVE üöó  [0.19h (+0.50h prep)]\n",
      "  Baie de Quenneville (5)   -> McGill                    : DRIVE üöó  [0.18h (+0.50h prep)]\n",
      "\n",
      "üìä  DETAILED CATCH LOG (Itemized List)\n",
      "\n",
      "  üìç Baie de Quenneville (ID:5) (Total Fishing Time: 4.00h)\n",
      "     TYPE     SPECIES              BAIT     STATUS\n",
      "     -------- -------------------- -------- ---------------\n",
      "     TARGET   Largemouth bass      soft     ‚úÖ KEEP\n",
      "     TARGET   Largemouth bass      soft     ‚úÖ KEEP\n",
      "     TARGET   Largemouth bass      soft     ‚úÖ KEEP\n",
      "\n",
      "  üìç Lake saint louie (ID:13) (Total Fishing Time: 3.93h)\n",
      "     TYPE     SPECIES              BAIT     STATUS\n",
      "     -------- -------------------- -------- ---------------\n",
      "     TARGET   Largemouth bass      soft     ‚úÖ KEEP\n",
      "     TARGET   Largemouth bass      soft     ‚úÖ KEEP\n",
      "\n",
      "  üìç Baie de Valois (ID:16) (Total Fishing Time: 1.53h)\n",
      "     TYPE     SPECIES              BAIT     STATUS\n",
      "     -------- -------------------- -------- ---------------\n",
      "     TARGET   Largemouth bass      soft     ‚úÖ KEEP\n",
      "===============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "\n",
    "# ============================================================\n",
    "#  PART 1: INTERACTIVE USER INPUT\n",
    "# ============================================================\n",
    "\n",
    "def get_input_list(prompt_text):\n",
    "    raw = input(prompt_text)\n",
    "    if not raw.strip(): return []\n",
    "    return [x.strip() for x in raw.split(',')]\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"      >>> FISHING TRIP CONFIGURATOR (EFFICIENCY MODE) <<<\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Target Species\n",
    "print(\"\\n[1] Target Species\")\n",
    "print(\"    Examples: Smallmouth Bass, Walleye, Northern pike\")\n",
    "user_species = get_input_list(\"üëâ Enter species: \")\n",
    "if not user_species: user_species = [\"Smallmouth Bass\", \"Walleye\"]\n",
    "\n",
    "# 2. Preferred Bait\n",
    "print(\"\\n[2] Preferred Baits\")\n",
    "print(\"    Options: soft, hard, natural\")\n",
    "user_baits_raw = get_input_list(\"üëâ Enter baits: \")\n",
    "user_baits = [b.lower() if b.lower()!='flies' else 'natural' for b in user_baits_raw]\n",
    "if not user_baits: user_baits = [\"soft\"]\n",
    "\n",
    "# 3. Rod\n",
    "print(\"\\n[3] Preferred Rod\")\n",
    "print(\"    Options: short, medium, long\")\n",
    "user_rods = [r.lower() for r in get_input_list(\"üëâ Enter rods: \")]\n",
    "if not user_rods: user_rods = [\"medium\"]\n",
    "\n",
    "# --- Parameters ---\n",
    "TIME_COST_PER_HOUR = 2.0   \n",
    "RELEASE_UTILITY    = 0.8  \n",
    "KEEP_BONUS         = 1\n",
    "\n",
    "# Bonus Weights\n",
    "BONUS_SPECIES = 1.7\n",
    "BONUS_BAIT    = 0.5\n",
    "BONUS_ROD     = 0.1\n",
    "BYCATCH_FACTOR = 0.3\n",
    "\n",
    "# Base Utility Weights\n",
    "W_HABITAT = 0.2\n",
    "W_SIZE    = 0.2\n",
    "W_THREAT  = 0.1\n",
    "W_STATUS  = 0.1\n",
    "\n",
    "print(f\"\\n‚úÖ Configured for Efficiency: Stops when Limit is reached.\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#  PART 2: OPTIMIZATION ENGINE\n",
    "# ============================================================\n",
    "\n",
    "# --- 2.1 Utilities ---\n",
    "def parse_dms_coord(coord_str):\n",
    "    if not isinstance(coord_str, str): return np.nan, np.nan\n",
    "    clean_s = re.sub(r\"[^0-9\\.NSEWnsew\\-]\", \" \", coord_str).strip().upper()\n",
    "    matches = re.findall(r'(\\d+)\\s+(\\d+)\\s+(\\d+(?:\\.\\d+)?)\\s*([NSEW])', clean_s)\n",
    "    if len(matches) >= 2:\n",
    "        def dms(d, m, s, h):\n",
    "            val = float(d) + float(m)/60 + float(s)/3600\n",
    "            return -val if h in ['S', 'W'] else val\n",
    "        return dms(*matches[0]), dms(*matches[1])\n",
    "    d = re.findall(r'(-?\\d+\\.\\d+)', clean_s)\n",
    "    if len(d) >= 2: return float(d[0]), float(d[1])\n",
    "    return np.nan, np.nan\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    if any(pd.isna([lat1, lon1, lat2, lon2])): return np.nan\n",
    "    R, p = 6371.0, math.pi / 180\n",
    "    a = 0.5 - math.cos((lat2-lat1)*p)/2 + math.cos(lat1*p) * math.cos(lat2*p) * (1-math.cos((lon2-lon1)*p))/2\n",
    "    return 2 * R * math.asin(math.sqrt(a))\n",
    "\n",
    "def extract_name(c): \n",
    "    m = re.search(r\"\\((.*?)\\)\", c)\n",
    "    return m.group(1).strip() if m else c.replace(\"SPECIES\", \"\").strip()\n",
    "\n",
    "def norm_str(s): return re.sub(r\"[^a-z]\", \"\", str(s).lower())\n",
    "\n",
    "# --- 2.2 Data Loading ---\n",
    "fish_clean = fish_clean.sort_values(\"Catches\", ascending=False).drop_duplicates(subset=[\"Name\"], keep=\"first\").sort_index().reset_index(drop=True)\n",
    "fish_clean[\"District\"] = fish_clean[\"District\"].fillna(\"Unknown\")\n",
    "\n",
    "fish_species_names = sorted({extract_name(c) for c in species_cols_final})\n",
    "fish_species_norm = {s: norm_str(s) for s in fish_species_names}\n",
    "species_meta[\"Fish_norm\"] = species_meta[\"Fish\"].apply(norm_str)\n",
    "species_mapping = {}\n",
    "for s in fish_species_names:\n",
    "    m = species_meta.index[species_meta[\"Fish_norm\"] == fish_species_norm[s]].tolist()\n",
    "    if m: species_mapping[s] = m[0]\n",
    "\n",
    "S = sorted(species_mapping.keys())\n",
    "I = list(fish_clean.index)\n",
    "\n",
    "species_meta[\"Lure_Clean\"] = species_meta[\"Lure\"].dropna().str.strip().str.lower().replace(\"flies\", \"natural\")\n",
    "T = sorted(species_meta[\"Lure_Clean\"].dropna().unique().tolist())\n",
    "districts = sorted(fish_clean[\"District\"].unique().tolist())\n",
    "\n",
    "lure_map, w_score_map, threat_map, status_map = {}, {}, {}, {}\n",
    "for s in S:\n",
    "    idx = species_mapping[s]\n",
    "    lure_map[s] = str(species_meta.loc[idx, \"Lure_Clean\"])\n",
    "    w_score_map[s] = species_meta.loc[idx, \"Weighted Score\"]\n",
    "    st = str(species_meta.loc[idx, \"IUCN Status\"]).lower()\n",
    "    status_map[s] = 1.0 if \"critically\" in st else (0.8 if \"endangered\" in st else 0.0)\n",
    "    th = str(species_meta.loc[idx, \"Threat to humans\"]).lower()\n",
    "    threat_map[s] = 1.0 if \"pest\" in th else 0.0\n",
    "\n",
    "w_min, w_max = min(w_score_map.values()), max(w_score_map.values())\n",
    "def norm(v,mn,mx): return 0.5 if mx==mn else (v-mn)/(mx-mn)\n",
    "size_hat = {(i,s): norm(w_score_map[s], w_min, w_max) for i in I for s in S}\n",
    "\n",
    "s_min, s_max = fish_clean[\"Star\"].min(), fish_clean[\"Star\"].max()\n",
    "habitat_hat = {i: norm(fish_clean.loc[i,\"Star\"], s_min, s_max) for i in I}\n",
    "r_class = {i: \"medium\" for i in I}\n",
    "\n",
    "col_map = {extract_name(c): c for c in species_cols_final if extract_name(c) in S}\n",
    "presence = {(i, s): fish_clean.loc[i, col_map[s]] for i in I for s in S}\n",
    "Omega = [(i, s, lure_map[s]) for i in I for s in S \n",
    "         if presence[(i,s)] == 1 and lure_map[s] in T]\n",
    "\n",
    "# --- 2.3 Efficiency ---\n",
    "avg_time_per_fish = {s: 1.5 for s in S} \n",
    "hard_list = [\"Muskellunge\", \"Sturgeon\", \"Walleye\", \"Lake trout\", \"Northern pike\", \"Catfish\", \"Striped bass\", \"Carpe\", \"Goldeye\"]\n",
    "for hs in hard_list: \n",
    "    if hs in avg_time_per_fish: avg_time_per_fish[hs] = 4.0\n",
    "\n",
    "is_easy = {s: (avg_time_per_fish[s] < 3.0) for s in S}\n",
    "mean_c = fish_clean[\"Catches\"].mean()\n",
    "if mean_c == 0: mean_c = 1.0\n",
    "Catch_Rate = {}\n",
    "for (i, s, t) in Omega:\n",
    "    base_r = 1.0 / avg_time_per_fish[s]\n",
    "    site_mult = max(0.5, min(1.5, 0.8 + 0.4*(fish_clean.loc[i,\"Catches\"]/mean_c)))\n",
    "    Catch_Rate[(i,s,t)] = base_r * site_mult\n",
    "\n",
    "# --- 2.4 Travel ---\n",
    "SPEED_D, SPEED_W, PENALTY = 60.0, 4.0, 0.5\n",
    "DEPOT = (45.5048, -73.5772)\n",
    "coords = {i: parse_dms_coord(fish_clean.loc[i, \"Coordinates\"]) for i in I}\n",
    "coords[\"depot\"] = DEPOT\n",
    "I0 = [\"depot\"] + I\n",
    "\n",
    "tau_d, tau_w = {}, {}\n",
    "for i in I0:\n",
    "    for j in I0:\n",
    "        if i == j: tau_d[(i,j)] = tau_w[(i,j)] = 0.0\n",
    "        else:\n",
    "            d = haversine(*coords[i], *coords[j])\n",
    "            if pd.isna(d): tau_d[(i,j)] = tau_w[(i,j)] = 1000.0\n",
    "            else:\n",
    "                tau_d[(i,j)] = d / SPEED_D\n",
    "                tau_w[(i,j)] = (d / SPEED_W) if d < 100 else 1000.0\n",
    "\n",
    "# --- 2.5 Model ---\n",
    "m = gp.Model(\"FishingTrip\")\n",
    "\n",
    "g = m.addVars(districts, vtype=GRB.BINARY, name=\"g\")\n",
    "y = m.addVars(I, vtype=GRB.BINARY, name=\"y\")\n",
    "x = m.addVars(Omega, vtype=GRB.BINARY, name=\"x\")\n",
    "h = m.addVars(Omega, lb=0.0, vtype=GRB.CONTINUOUS, name=\"h\")\n",
    "b = m.addVars(Omega, vtype=GRB.BINARY, name=\"b\") \n",
    "K = m.addVars(Omega, vtype=GRB.INTEGER, lb=0, name=\"K\")\n",
    "Total_Catch_Var = m.addVars(Omega, lb=0.0, vtype=GRB.CONTINUOUS, name=\"TC\")\n",
    "\n",
    "v = m.addVars(I0, I0, vtype=GRB.BINARY, name=\"v\")\n",
    "D = m.addVars(I0, I0, vtype=GRB.BINARY, name=\"Drive\")\n",
    "W = m.addVars(I0, I0, vtype=GRB.BINARY, name=\"Walk\")\n",
    "U = m.addVars(I, vtype=GRB.INTEGER, lb=0, name=\"U\") \n",
    "\n",
    "# Params (Fixed Syntax Error Here)\n",
    "alpha = {s: (BONUS_SPECIES if s in user_species else 0.0) for s in S}\n",
    "beta = {t: (BONUS_BAIT if t in user_baits else 0.0) for t in T}\n",
    "delta = {\"short\": 0.0, \"medium\": 0.0, \"long\": 0.0}\n",
    "for r in user_rods: \n",
    "    if r in delta: \n",
    "        delta[r] = BONUS_ROD\n",
    "\n",
    "# --- OBJECTIVE ---\n",
    "expr_util = 0\n",
    "total_time_expr = 0\n",
    "\n",
    "travel_time_expr = gp.quicksum((tau_d[(i,j)]+PENALTY)*D[i,j] + tau_w[(i,j)]*W[i,j] \n",
    "                               for i in I0 for j in I0 if i!=j)\n",
    "total_time_expr += travel_time_expr\n",
    "\n",
    "for (i,s,t) in Omega:\n",
    "    rod_bonus = delta.get(r_class[i], 0.0)\n",
    "    \n",
    "    # Weighted Base Utility\n",
    "    base_util = (W_HABITAT * habitat_hat[i]) + \\\n",
    "                (W_SIZE * size_hat[(i,s)]) + \\\n",
    "                (W_THREAT * threat_map[s]) + \\\n",
    "                (W_STATUS * status_map[s])\n",
    "    \n",
    "    # Experience Utility\n",
    "    expr_util += (base_util + alpha[s] + beta[t] + rod_bonus) * h[(i,s,t)]\n",
    "    \n",
    "    # Catch Utility\n",
    "    expr_util += (RELEASE_UTILITY * Total_Catch_Var[(i,s,t)]) + (KEEP_BONUS * K[(i,s,t)])\n",
    "    \n",
    "    total_time_expr += h[(i,s,t)]\n",
    "\n",
    "m.setObjective(expr_util - (TIME_COST_PER_HOUR * total_time_expr), GRB.MAXIMIZE)\n",
    "\n",
    "# --- Constraints ---\n",
    "m.addConstr(gp.quicksum(g[d] for d in districts) == 1)\n",
    "for i in I: m.addConstr(y[i] <= g[fish_clean.loc[i,\"District\"]])\n",
    "\n",
    "H_MAX, MIN_T = 4.0, 0.25\n",
    "\n",
    "for (i,s,t) in Omega:\n",
    "    m.addConstr(x[(i,s,t)] <= y[i])\n",
    "    m.addConstr(h[(i,s,t)] <= H_MAX * x[(i,s,t)])\n",
    "    m.addConstr(h[(i,s,t)] >= MIN_T * x[(i,s,t)])\n",
    "    \n",
    "    target_c = Catch_Rate[(i,s,t)] * h[(i,s,t)]\n",
    "    bycatch_sum = 0\n",
    "    if is_easy[s]:\n",
    "        for (idx_o, s_o, t_o) in Omega:\n",
    "            if idx_o == i and t_o == t and s_o != s and is_easy[s_o]:\n",
    "                bycatch_sum += (Catch_Rate[(i,s,t)] * BYCATCH_FACTOR * h[(idx_o, s_o, t_o)])\n",
    "    m.addConstr(Total_Catch_Var[(i,s,t)] == target_c + bycatch_sum)\n",
    "    \n",
    "    m.addConstr(K[(i,s,t)] <= Total_Catch_Var[(i,s,t)])\n",
    "    m.addConstr(K[(i,s,t)] <= 10.0 * y[i])\n",
    "\n",
    "for i in I:\n",
    "    site_h = gp.quicksum(h[(idx, s, t)] for (idx, s, t) in Omega if idx == i)\n",
    "    m.addConstr(site_h <= H_MAX * y[i])\n",
    "\n",
    "m.addConstr(gp.quicksum(v[\"depot\",j] for j in I) == 1)\n",
    "m.addConstr(gp.quicksum(v[i,\"depot\"] for i in I) == 1)\n",
    "for i in I:\n",
    "    m.addConstr(gp.quicksum(v[i,j] for j in I0 if j!=i) == y[i])\n",
    "    m.addConstr(gp.quicksum(v[j,i] for j in I0 if j!=i) == y[i])\n",
    "for i in I0:\n",
    "    for j in I0: \n",
    "        if i!=j: m.addConstr(D[i,j] + W[i,j] == v[i,j])\n",
    "\n",
    "N = len(I)\n",
    "for i in I:\n",
    "    for j in I: \n",
    "        if i!=j: m.addConstr(U[i] - U[j] + N*v[i,j] <= N-1)\n",
    "\n",
    "T_CAP = 12.0\n",
    "m.addConstr(total_time_expr <= T_CAP)\n",
    "for (i,j), val in tau_d.items():\n",
    "    if i!=j and val*SPEED_D > 3.0: m.addConstr(W[i,j] == 0)\n",
    "\n",
    "Limit_s = {s: 6 for s in S}\n",
    "for s in S: m.addConstr(gp.quicksum(K[(i,s,t)] for i in I for t in T if (i,s,t) in Omega) <= Limit_s[s])\n",
    "GLOBAL_LIMIT = 6\n",
    "m.addConstr(gp.quicksum(K[(i,s,t)] for (i,s,t) in Omega) <= GLOBAL_LIMIT)\n",
    "\n",
    "# ============================================================\n",
    "#  PART 3: OUTPUT\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n--- Optimizing ---\")\n",
    "m.Params.TimeLimit = 60\n",
    "m.optimize()\n",
    "\n",
    "if m.status in [GRB.OPTIMAL, GRB.TIME_LIMIT]:\n",
    "    curr, route_ids = \"depot\", []\n",
    "    t_d_tot, t_p_tot, t_w_tot = 0,0,0\n",
    "    while True:\n",
    "        found = False\n",
    "        for j in I0:\n",
    "            if curr != j and v[curr, j].X > 0.5:\n",
    "                mode = \"DRIVE üöó\" if D[curr, j].X > 0.5 else \"WALK üö∂\"\n",
    "                t = tau_d[(curr, j)] if \"DRIVE\" in mode else tau_w[(curr, j)]\n",
    "                p = PENALTY if \"DRIVE\" in mode else 0.0\n",
    "                if \"DRIVE\" in mode: t_d_tot+=t; t_p_tot+=p\n",
    "                else: t_w_tot+=t\n",
    "                route_ids.append((curr, j, mode, t, p))\n",
    "                curr = j; found = True; break\n",
    "        if not found or curr == \"depot\": break\n",
    "\n",
    "    fishing_data = []\n",
    "    tot_fish_time, tot_catch_int, tot_kept_int = 0, 0, 0\n",
    "    \n",
    "    for i in I:\n",
    "        if y[i].X > 0.5:\n",
    "            name = fish_clean.loc[i, \"Name\"]\n",
    "            disp_name = f\"{name} (ID:{i})\"\n",
    "            acts = []\n",
    "            site_time = 0.0\n",
    "            \n",
    "            for (idx, s, t) in Omega:\n",
    "                if idx == i:\n",
    "                    hr_spent = h[(idx,s,t)].X\n",
    "                    catch_val = Total_Catch_Var[(idx,s,t)].X\n",
    "                    kp = int(K[(idx,s,t)].X)\n",
    "                    \n",
    "                    c_int = int(catch_val + 1e-5)\n",
    "                    if c_int < kp: c_int = kp\n",
    "                    \n",
    "                    if hr_spent > 0.01 or c_int > 0:\n",
    "                        type_lbl = \"TARGET\" if hr_spent > 0.01 else \"RANDOM\"\n",
    "                        acts.append((s, t, c_int, kp, type_lbl))\n",
    "                        site_time += hr_spent\n",
    "                        tot_catch_int += c_int\n",
    "                        tot_kept_int += kp\n",
    "            \n",
    "            if acts:\n",
    "                fishing_data.append((disp_name, site_time, acts))\n",
    "                tot_fish_time += site_time\n",
    "\n",
    "    tot_rel_int = tot_catch_int - tot_kept_int\n",
    "    total_duration = t_d_tot + t_p_tot + t_w_tot + tot_fish_time\n",
    "\n",
    "    print(\"\\n\" + \"‚îÅ\"*95)\n",
    "    print(f\"üé£  FISHING TRIP SUMMARY (Obj: {m.objVal:.2f})\")\n",
    "    print(\"‚îÅ\"*95)\n",
    "    print(f\"‚è±Ô∏è  Duration : {total_duration:.2f} / {T_CAP} hrs\")\n",
    "    if total_duration < T_CAP - 0.5:\n",
    "        print(f\"   (‚ö†Ô∏è Trip ended early! Bag limit reached or cost outweighed benefit)\")\n",
    "    \n",
    "    print(f\"üêü  Real Catch: {tot_catch_int}  (Keep: {tot_kept_int} | Release: {tot_rel_int})\")\n",
    "    print(f\"üìç  Districts : {fish_clean.loc[I[0],'District']}\")\n",
    "    print(\"-\" * 95)\n",
    "    \n",
    "    print(\"\\nüöó  TRIP ITINERARY\")\n",
    "    for (u, v_node, mode, t, p) in route_ids:\n",
    "        nu = \"McGill\" if u == \"depot\" else f\"{fish_clean.loc[u, 'Name']} ({u})\"\n",
    "        nv = \"McGill\" if v_node == \"depot\" else f\"{fish_clean.loc[v_node, 'Name']} ({v_node})\"\n",
    "        ts = f\"{t:.2f}h\" + (f\" (+{p:.2f}h prep)\" if p>0 else \"\")\n",
    "        print(f\"  {nu:<25} -> {nv:<25} : {mode:<8} [{ts}]\")\n",
    "\n",
    "    print(\"\\nüìä  DETAILED CATCH LOG (Itemized List)\")\n",
    "    if fishing_data:\n",
    "        for (site_name, st, acts) in fishing_data:\n",
    "            print(f\"\\n  üìç {site_name} (Total Fishing Time: {st:.2f}h)\")\n",
    "            print(f\"     {'TYPE':<8} {'SPECIES':<20} {'BAIT':<8} {'STATUS'}\")\n",
    "            print(f\"     {'-'*8} {'-'*20} {'-'*8} {'-'*15}\")\n",
    "            cnt = 0\n",
    "            for (s, t, catch, kp, type_lbl) in acts:\n",
    "                if catch == 0: \n",
    "                    print(f\"     {type_lbl:<8} {s:<20} {t:<8} (No Catch)\")\n",
    "                for k in range(catch):\n",
    "                    status = \"‚úÖ KEEP\" if k < kp else \"üëã REL\"\n",
    "                    print(f\"     {type_lbl:<8} {s:<20} {t:<8} {status}\")\n",
    "                    cnt += 1\n",
    "            if cnt == 0 and st > 0: print(\"     (No fish caught here)\")\n",
    "    else:\n",
    "        print(\"  (No fishing activities planned)\")\n",
    "    print(\"=\"*95)\n",
    "else:\n",
    "    print(\"No optimal solution found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74162000-f112-438e-a5a2-68b638af86c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
